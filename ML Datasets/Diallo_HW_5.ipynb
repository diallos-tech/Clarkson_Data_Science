{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 05\n",
    "# Due: Monday July 8th, 2024, 3:59 PM\n",
    "# Late submissions until July 10th, 3:59 PM\n",
    "## Instructions:\n",
    "1. Once the notebook is completed, export to .py file.  Submit both the notebook and the .py file.  To do this, click export at the top of the notebook or ctrl + shift + p at the top of the notebook and type in export.  Export to python file should show up as a search result.  Also:\n",
    "    - Ensure that your .py file is an exact replica of your .ipynb file.  \n",
    "    - Ensure your .py and .ipynb files run successfully without any errors.  You should be able to click `Run All` in VS Code and run the notebook without error before converting to a .py file.  When completed, you should be able to run the .py file from the terminal or command prompt.\n",
    "2. DO NOT submit the data from the assignment and keep your data file and python file in the same directory. Do not use your local directory path to read files (e.g., avoid using paths like C:/your/directory/file.csv).  Just read in the file directly as if though it was in the same directory as your .ipynb file.  DO NOT CHANGE THE NAME OF THE FILE....\n",
    "3. Whenever we ask to .head(10) the results or print out a value, please use `print()` so for example `print(df.head(10))`. Print only the answers to the questions that have been asked.  Do not print the head of a dataset unless explicitly asked. \n",
    "4. Whenever displaying a graph use `plt.show()`\n",
    "5. For theoretical answers/short answers, please use print() (e.g., print(\"your answer\")).\n",
    "6. Wherever we have code displayed to print out values, use that code as a template to print out your output.  For example, if we give you `print(f'Threshold for best accuracy: {}')` please use code in this style to print out your output.  For some questions, this is only a template as we expect you to print out multiple answers (For example....Fit a linear regression model to each of the 5 features INDIVUDALLY and print out the slope and intercept for each. (Don't forget train/test split) requires you use the template for each feature)\n",
    "7. Do not include pip install commands in your code. You can assume that all required libraries are already installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: SVM With Real Estate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "\n",
    "For this assignment we are going to use the northeast_realestate.parquet file that we did in the first assignment.  We will basically:\n",
    "\n",
    "1. Complete some basic EDA\n",
    "2. Filter out bad data\n",
    "3. Create a train test split\n",
    "4. Fit an SVM and a Logistic Regression to compare\n",
    "5. Use GridSearchCV to find the best parameters for an SVM and analyze the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import data and packages here.  Import parquet file using `pd.read_parquet(\"northeast_realestate.parquet\")`.  Print out the head of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Print out the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a new feature like we did in class called `'citystate'` that is a combination of the city and state separated by an underscore.  Print out the head of this new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Filter only on 'Staten Island_New York','Worcester_Massachusetts','Manhattan_New York' and 'Portland_Maine' and print out the shape of the resultant data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. For each column in this new data frame, print out the number of null values, the number of not null values and the percent of nulls in each column. You can either put all values in a data frame and print it out or loop through the columns and print them out separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((f'Column: {}\\n Number null: {}\\n Number not null: {}\\n Proportion null: {}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Select only the 'price','bed','bath','house_size' and 'citystate' variables and drop the nulls and drop the duplicates.  Print the head of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Print the shape of this new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Create a pair scatter plot of all the numeric variables (all the variables except the citystate).  I think we learned how to do this in `03_data_prep_and_preprocessing_notebook_02.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Which variables seem to be correlated with eachother?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Create two column plots displaying the count of observations for all values of bed and bath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Print out the row(s) for the properties with the highest number of beds.  Do any bed values seem like outliers?  Does the price seem to match your intuition about the number of beds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Row with highest number of beds:\\n{}')\n",
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Create a histogram of the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Is the price skewed?  What type of transformation (see `03_data_prep_and_preprocessing_notebook_02.ipynb`) should we use to transform a value with such extreme values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Plot a histogram of the transformed price.  Does it look more normal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()\n",
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Do the same for house_size. Plot the histogram of house_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Should house_size be transformed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Plot a histogram of transformed house_size.  Does is appear more normal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()\n",
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Create a correlation matrix for the numeric variables.   Use a heatmap and the \"flare\" color palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19.  What variables are most correlated?  If we were to complete PCA in this assignment (which we aren't), which X variables would be good candidates for combining for PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.  Calculate and print out the percentage of rows by citystate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Is the data set balanced?  Which citystate combination occurs the most?  The least?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. Create your X and y variables.  Transform house_size and price the way we did above.  Your y, or target variable, should be citystate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. Create a train test split.  Use 0.20 test size and random_state = 42.  Print the shape of your x train, x test, y train and y test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. Print out the proportion of observations by citystate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25.  Does the distribution of values match the overall data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26. Override your train test split, except stratify by the y variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27. Print out the distribution of y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28.  Is the distribution of your y values closer to the original dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29. Scale your training data using `fit_transform` and then use `transform` to transform the test data as well using the same scaler (don't call `fit_transform again`, just `fit`).  Print out the head of your scaled X data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30. Create a separate scatter plot of your training data (or use a FacetGrid and use col='citystate') for each citystate with price on the x axis and house_size on the y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31.  Create a single scatter plot with price on the x and house_size on the y.  Color the observations by citystate and add a legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32. Which citystates seem like they might be the most easy to categorize or separate using these two variables, from what you can see in your graphs.  Which ones seem like they will be more difficult to separate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33. Fit a logistic regression and print out the accuracy_score and f1_score (use the macro average) for the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(),\n",
    "      metrics.f1_score())\n",
    "\n",
    "\n",
    "print(metrics.accuracy_score(),\n",
    "      metrics.f1_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34. Do the same, except with a SVC.  Use C=1 and gamma=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(),\n",
    "      metrics.f1_score())\n",
    "\n",
    "\n",
    "print(metrics.accuracy_score(),\n",
    "      metrics.f1_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35. Which model seems to perform better on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36. Do grid search to find the best hyperparameters\n",
    "\n",
    "- Use KFold and n_splits=5 and a random_state of 7.  Set shuffle=True\n",
    "- Use the params dictionary given (you should calculate 175 models)\n",
    "- Use your scaled data\n",
    "- Print out the best score and best parameters.  Look at the sklearn documentation for how to select the best score and parameters from the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {'C': [0.1, 1, 10, 100, 1000, 10000, 20000],\n",
    "          'gamma': [1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "\n",
    "print(f'Best Score: {}')\n",
    "print(f'Best Parameters: {}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "37. Do the same as above, except use your unscaled data.  Print out the best score and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {'C': [0.1, 1, 10, 100, 1000, 10000, 20000],\n",
    "          'gamma': [1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "\n",
    "print(f'Best Score: {}')\n",
    "print(f'Best Parameters: {}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "38.  Which combination of data and parameters (scaled vs unscaled, gamma, C) seem to produce the best model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "39. Fit a final model using your best parameters above on the scaled data.  Print out the accuracy_score and f1_score (use macro average) for the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(),\n",
    "      metrics.f1_score())\n",
    "\n",
    "\n",
    "print(metrics.accuracy_score(),\n",
    "      metrics.f1_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40. Is the f1 score for the test set (from the previous question, question 39) close to the f1 score you calculated for your best model above (question 36) through cross validation?  Said another way, would you say that your f1 score found in the grid search (question 36) is a good approximation of your actual f1 test score (from the previous question, question 39)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41. Plot a confusion matrix using `metrics.ConfusionMatrixDisplay.from_predictions`.  Use `normalize='true'` and `values_format=\".0%\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_predictions(??,\n",
    "                                                ??,\n",
    "                                                normalize='true',\n",
    "                                                values_format=\".0%\",\n",
    "                                                xticks_rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "42. Where does there seem to be the most confusion (i.e. which classes seem to be confused for one another)?  Does this make sense given your scatter plots in questions 30-31?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "43. Use `metrics.classification_report` on the test data.  Print out the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "44. What do your f1 scores tell you about which categories are easiest to classify and which are hardest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "45. What recommendations would you give someone to improve their model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus (10 Points)\n",
    "\n",
    "46. Use a label encoder on the y variable train data to encode as numbers instead of strings.  Use the same label encoder on the test data to transform that data as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "47. Fit a model on only price and house_size.  Use the scaled data and the parameters from your best model above (use an SVC, not Logistic Regression) and the newly encoded y train as your y variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "48. Print out the training and test accuracy and f1 scores (use macro average).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(),\n",
    "      metrics.f1_score())\n",
    "\n",
    "\n",
    "print(metrics.accuracy_score(),\n",
    "      metrics.f1_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "49. How does the test accuracy and f1_scores seem to compare to our model above that had bed and bath in them?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50. Plot a confusion matrix with `normalize='true'` and `values_format=\".0%\"`.  Create a title indicating which labels from the label encoder correspond to which string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_predictions(??,\n",
    "                                                ??,\n",
    "                                                normalize='true',\n",
    "                                                values_format=\".0%\",\n",
    "                                                xticks_rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "51. Where does the confusion seem to be?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "52. Plot the decision boundary with only scatter plot for Manhattan and Worchester\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "53. Plot the decision boundary with scatter plot for all four categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "54. Do your decision boundaries make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Your answer here\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
